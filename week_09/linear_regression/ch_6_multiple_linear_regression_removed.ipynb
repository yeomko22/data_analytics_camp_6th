{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f6b97a-b39d-4e0f-85a5-0d5e2877ed97",
   "metadata": {},
   "source": [
    "# ch 6. multiple linear regression \n",
    "\n",
    "## 다중 선형 회귀\n",
    "독립 변수의 개수가 2개 이상인 선형 회귀 모델을 다중 선형 회귀라고 부릅니다. 다중 선형 회귀 모형은 아래와 같습니다.\n",
    "\n",
    "$$Y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\beta_{k}X_{k}+\\epsilon$$\n",
    "\n",
    "$$X_{j}:\\text{j 번째 독립 변수}$$\n",
    "$$Y:\\text{종속 변수}$$\n",
    "$$\\beta_{0}:\\text{절편}$$\n",
    "$$\\beta_{j}:\\text{j번째 기울기}$$\n",
    "$$\\epsilon:\\text{오차}$$\n",
    "\n",
    "우리가 하고 싶은 것은 데이터로부터 회귀 식을 추정하는 것입니다. 추정된 회귀 식은 아래와 같습니다.\n",
    "\n",
    "$$\\hat{y_{i}}=b_{0}+b_{1}x_{1i}+b_{2}x_{2i}+...+b_{k}x_{ki}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75192a2-7df0-444b-9875-f88b20e57bcb",
   "metadata": {},
   "source": [
    "## 최소 제곱법\n",
    "\n",
    "다중 선형 회귀도 단순 선형 회귀와 마찬가지로 최소 제곱법으로 회귀식을 도출할 수 있습니다.\n",
    "\n",
    "$$(b_{0},b_{1}, ..., b_{k})=argmin\\sum_{i=1}^{n}\\epsilon_{i}^2=argmin\\sum_{i=1}^{n}(y_{i}-\\beta_{0}-\\beta_{1}x_{1i}- ... -\\beta_{k}x_{ki})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc6049-06ea-4335-8cc9-8c125f2aa968",
   "metadata": {},
   "source": [
    "이렇게 도출한 회귀 계수 b_j는 나머지 독립 변수들을 모두 고정한 채, j 번째 독립변수를 1단위 변화할 때 종속 변수의 변화량이라고 해석할 수 있습니다.\n",
    "\n",
    "다중 선형 회귀의 최소 제곱 추정은 maximum likelihood estimation, ordinary least square 등의 방법으로 계산할 수 있습니다. 각각에 대해 궁금하신 분들은 아래 링크를 참고해주세요.\n",
    "\n",
    "- MLE: https://laoonlee.tistory.com/15\n",
    "- OLS: https://laoonlee.tistory.com/14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c228cd2-f324-48f5-9067-de417d675e08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 변수 선택\n",
    "\n",
    "회귀식에 포함될 독립 변수를 고르는 것을 변수 선택이라고 합니다. \n",
    "\n",
    "### 전진선택법\n",
    "\n",
    "forward selection method라고도 부릅니다. 더 이상 유의한 추가 변수가 없을 때까지 변수를 하나씩 더해가는 방법입니다. 먼저 k개의 독립변수마다 각각 단순 회귀 모형을 만듭니다. 여기서 SSR이 크거나, SSE가 작거나, F 값이 크거나, t 값이 크거나 R^2 값이 큰 것을 기준으로 적합이 제일 잘 된 것을 선택합니다. \n",
    "\n",
    "### 후진 제거법\n",
    "\n",
    "backward elimination method라고도 부릅니다. 먼저 k개의 독립변수들을 모두 포함하는 모델을 만듭니다. 이 중 가장 유의하지 않은 독립변수를 제거하는 과정을 반복합니다. 모든 회귀 계수가 유의할 때까지 반복합니다.\n",
    "\n",
    "### 단계적 선택법\n",
    "\n",
    "stepwise selection method라고도 부릅니다. 전진 선택과 후진 제거를 적절히 섞어서 변수를 찾습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c99b0e-458e-446d-99af-8f12e570fb68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 집 값 예측하기 예제\n",
    "\n",
    "집 값 예측 모델을 다중 선형회귀를 사용해서 학습해보겠습니다. 전진 선택법을 사용하여 다중 공선성 발생 여부를 체크하면서 price와 선형 관계성이 높은 독립 변수들을 추가해보겠습니다.\n",
    "\n",
    "### 데이터 셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c3ce-ca5a-4e66-8836-028f01a64cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f2951c-09a0-46de-b983-79e2635b3dc5",
   "metadata": {},
   "source": [
    "### 독립 변수 선택\n",
    "\n",
    "히트맵을 그린 뒤, price와 관련성이 높은 독립 변수를 하나 선택하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c9edd-d398-4e50-a2d7-b714aa1d34f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b19e6aa-8f02-4b03-a3d7-2af08baac799",
   "metadata": {},
   "source": [
    "### 단순 선형회귀 모델 학습\n",
    "\n",
    "독립 변수 하나만 선택하여 선형 회귀 모델을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf7398-3abc-4d6c-baaf-07ae176f5b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a005687b-75cf-4289-b6ba-a669b2e3b38c",
   "metadata": {},
   "source": [
    "### 전진 선택법으로 다중 선형 회귀 모델 학습\n",
    "\n",
    "price와 연관 관계가 높은 독립변수를 추가해가며 모델을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146959e-2496-4ade-a1f0-c9a547d242f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879d1395-00dc-4b68-a51d-07f1e9b583e3",
   "metadata": {},
   "source": [
    "모든 회귀 계수들이 유의하고, R square 값이 0.490에서 0.532로 대폭 증가한 것을 확인할 수 있습니다. 한번 더 독립 변수를 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda21a2a-38c6-457e-bdb7-0cc7f5fe90dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a712a62e-8574-48fa-aee7-4a56d5fc3342",
   "metadata": {},
   "source": [
    "이번에도 모든 회귀 계수들이 유의하며, R square 값이 0.532에서 0.57로 증가했습니다. 이처럼 단순 선형 회귀 모델에서 독립 변수를 추가해가면서 다중 선형 회귀 모델을 학습시키는 기법이 전진 선택법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6b5ddf-e92b-4708-b237-7d6304c9b50b",
   "metadata": {},
   "source": [
    "### 후진 제거법으로 다중 선형 회귀 모델 학습\n",
    "\n",
    "독립 변수를 모두 사용하여 다중 선형 회귀 모델을 학습시킨 뒤, 유의하지 않은 독립 변수들을 제거하는 후진 제거법으로 다중 선형 회귀 모델을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3a5c4-7acd-4bf3-a7a9-3257605e1df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da5436e-3d79-4881-bd21-86bf672c81d8",
   "metadata": {},
   "source": [
    "유의하지 않았던 sqft_lot 독립 변수를 제거한 뒤에 다시 학습을 시켜보면 모든 독립변수가 유의하다고 나옵니다. 그리고 독립 변수를 줄였음에도 R square 값이 동일하게 유지되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee26bbc-b508-401d-b153-c2f605c28aa0",
   "metadata": {},
   "source": [
    "## 다중 공선성\n",
    "\n",
    "다중 선형 회귀 모델은 다중 공선성이 발생했는지 여부를 진단해야합니다. 다중 공선성(multi colinearity)이란 독립 변수들 사이에 선형 독립성이 확보되지 못한 상태를 말합니다. 이는 독립 변수의 일부가 다른 독립 변수의 조합으로 표현될 수 있는 경우를 말합니다. 예를들어 주중 매출, 주말 매출, 주간 매출 컬럼이 있다면, 주간 매출은 주중 매출과 주말 매출의 합으로 표현될 수 있습니다.\n",
    "\n",
    "### 다중 공선성이 발생시키는 문제\n",
    "1. 파라미터 추정의 불안정성: 독립 변수들이 서로 설명력을 공유하게 되어 파라미터 추정이 불안정해집니다. 작은 변화가 모델의 파라미터에 큰 영향을 미치므로 추정된 파라미터의 신뢰도가 낮아집니다.\n",
    "\n",
    "2. 해석의 어려움: 다중 공선성으로 인해 독립 변수들의 개별적인 영향력을 파악하기 어려워집니다.\n",
    "\n",
    "3. 과도한 가중치 크기: 다중 공선성으로 인해 모델은 적절한 가중치를 찾지 못하고 변수들에 대해 과도한 가중치 크기를 할당하는 경향이 있습니다. 이로 인해 모델의 일반화 능력이 저하될 수 있습니다.\n",
    "\n",
    "다중 공선성 문제가 발생하면 다중 선형 회귀 모델 자체가 제대로 학습되지 않기 때문에 제거해주어야 합니다. 직접 한번 뚜렷한 선형 관계가 있는 독립변수들을 사용하여 다중 선형 회귀 모델을 학습시키고, 다중 공선성 문제를 진단해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82b206-9c4d-4e57-9e55-aaadcbbaf30d",
   "metadata": {},
   "source": [
    "### VIF를 이용한 다중 공선성 진단\n",
    " \n",
    "다중 공선성을 제거하는 가장 기본적인 방법은 다른 독립 변수에 의존하는 변수를 없애는 것입니다. 이는 VIF 값을 계산하여 구할 수 있습니다. VIF는 독립변수를 다른 독립변수로 선형회귀한 성능을 나타낸 것입니다. 𝑖번째 변수의 VIF는 다음과 같이 계산합니다.\n",
    "\n",
    "$$\\text{VIF}_i = \\frac{\\sigma^2}{(n-1)\\text{Var}[X_i]}\\cdot \\frac{1}{1-R_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487e4cd-989e-46e1-8f6b-45641aed7262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e890c673-dcac-40d9-b554-485b4a34ed07",
   "metadata": {},
   "source": [
    "VIF 값이 10이 넘어가면 해당 독립 변수가 다른 독립 변수에 의존한다고 봅니다. 이 경우, 서로 상관 관계가 높은 컬럼 중 가장 설명력이 높은 컬럼만 남기고 나머지 컬럼을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c4a62-3960-4652-879b-e873ad46528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a8b824-76d7-48f3-ae8f-30fb485db0ca",
   "metadata": {},
   "source": [
    "다중 공선성을 제거할 경우, R square 값이 떨어질 수 있습니다. 모델의 안정성과 해석 가능성을 우선으로 여기는 경우에는 다중 공선성을 제거하는 것이 바람직할 수 있습니다. 하지만 모델의 설명력(R-squared)을 최대화하는 데에 집중해야 하는 경우에는 다중 공선성을 제거하더라도 R-squared 값이 떨어질 수 있으며, 이런 경우에는 다른 평가 지표를 함께 고려하여 적절한 모델 선택을 해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f67053-f12d-4597-95ad-48b97092957a",
   "metadata": {},
   "source": [
    "### 그 외 다중 공선성 해결 방법\n",
    "\n",
    "다중 공선성 문제는 크게 3가지 해결 방법이 있습니다.\n",
    "\n",
    "1. 가장 설명력이 높은 변수를 제외하고 나머지 제거하기\n",
    "2. 주성분 분석 등 차원 축소 기법을 사용하여 각 컬럼들로 부터 주요 정보만 추출하기\n",
    "3. lasso, ridge 등 모델 학습 단계에서 가중치 조절하여 다중 공선성 효과 상쇄하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b282402-8187-4877-8317-725e5bbaa73b",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀 모델을 선택하는 상황\n",
    "\n",
    "독립 변수를 추가하거나 제거하면서 딜레마에 빠집니다. 어느 변수를 추가하면 다중 공선성은 발생하지만 R square가 증가하고, 어떤 변수를 전처리하였더니 오히려 R square가 감소하는 모습을 보입니다. 이처럼 다중 선형회귀 모델은 어떤 모델이 좋은 모델인지 기준을 명확히 내리는 것이 어렵습니다. \n",
    "\n",
    "만일 kaggle 경진대회 처럼 예측력 자체가 중요한 상황이라면 Decision Tree Regressor와 같은 모델을 선택하는 것이 더 좋습니다. 이 때, 평가 metric에 맞춰서 최대한 많은 독립변수와 파생변수를 생성하여 예측력이 뛰어난 모델을 만드는 것이 좋습니다.\n",
    "\n",
    "반대로 특정 독립변수가 한 단위 증가했을 때, 종속 변수가 얼만큼 영향을 받는지 등을 해석하는게 중요한 상황이라면, 다중 선형 회귀 모델을 선택하는 것이 좋습니다. 이는 예측력은 다소 떨어지지만, 독립변수와 종속 변수 간의 관계를 파악하기에 도움을 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06051ba-0c0a-4b41-8dc7-532af8cc44af",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 챕터에서는 다중 선형 회귀 모델에 대해서 배워봤습니다. 단순 선형 회귀를 여러개의 독립 변수에 대해서 확장한 개념이라 크게 어렵지 않았습니다. 다만, 이 때 독립 변수들끼리 선형 상관관계를 맺는 다중 공선성 문제가 등장한 다는 것을 반드시 기억하시기 바랍니다. 다중 공선성은 데이터 분석 직군에서 단골 면접 질문으로 등장하는 만큼, 개념과 진단 방법, 해결 방법을 잘 복습하시기 바랍니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
