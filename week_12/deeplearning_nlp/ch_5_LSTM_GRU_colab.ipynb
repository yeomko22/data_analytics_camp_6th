{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeomko22/data_analytics_camp_6th/blob/main/week_12/deeplearning_nlp/ch_5_LSTM_GRU_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOXnOpGpbShY"
      },
      "source": [
        "# ch 5. LSTM\n",
        "\n",
        "ì´ì „ ì±•í„°ì—ì„œëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœì˜ RNNì— ëŒ€í•´ì„œ ë°°ì›Œë´¤ìŠµë‹ˆë‹¤.  í•˜ì§€ë§Œ ë°”ë‹ë¼ RNNì€ ë°”ë‹ë¼ RNNì˜ ì‹œì (time step)ì´ ê¸¸ì–´ì§ˆ ìˆ˜ë¡ ì•ì˜ ì •ë³´ê°€ ë’¤ë¡œ ì¶©ë¶„íˆ ì „ë‹¬ë˜ì§€ ëª»í•˜ëŠ” í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤. ì¦‰, ì‹œí€€ìŠ¤ê°€ ê¸¸ì–´ì§ˆ ìˆ˜ë¡ ê³¼ê±°ì˜ ì •ë³´ê°€ ì†ì‹¤ë˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ë¥¼ ë³´ì™„í•˜ëŠ” ëª¨ë¸ì´ LSTMì…ë‹ˆë‹¤. ì´ëŠ” ì¥ê¸° ê¸°ì–µìœ¼ë¡œ í•„ìš”í•œ ì •ë³´ëŠ” ìœ ì§€í•˜ê³ , ë¶ˆí•„ìš”í•œ ê¸°ì–µì€ ì‚­ì œí•  ìˆ˜ ìˆëŠ” ê²Œì´íŠ¸ë¼ëŠ” ê°œë…ì„ RNNì— ì¶”ê°€í•œ ê²ƒì…ë‹ˆë‹¤. ì¥ê¸° ê¸°ì–µì„ íš¨ê³¼ì ìœ¼ë¡œ ë³´ì¡´í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ì™€ ì‹œê³„ì—´ ë¶„ì„ì— ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWXrSVE8f6VJ"
      },
      "source": [
        "## LSTM ì´ë¡ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhBiBKxGbVC2"
      },
      "source": [
        "### LSTM ê¸°ë³¸ êµ¬ì¡°\n",
        "\n",
        "LSTMì€ vanila RNNê³¼ ê¸°ë³¸ êµ¬ì¡°ëŠ” ë¹„ìŠ·í•©ë‹ˆë‹¤. ê° ì‹œì  ë³„ë¡œ ì…ë ¥ ê°’ì— ëŒ€í•´ì„œ ì˜ˆì¸¡ê°’ê³¼ hidden stateë¥¼ ê³„ì‚°í•˜ì—¬ ë‹¤ìŒ ìƒíƒœì— ì „ë‹¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGvZYE9Fm-KM"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzIY36-5npA7"
      },
      "source": [
        "ì´ì œ LSTMì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nxRTX4zntZ-"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/11.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqnbk7ZOoBxI"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/12.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poiss_hGnxRn"
      },
      "source": [
        "ë§¤ìš° ë³µì¡í•˜ê²Œ ìƒê²¼ìŠµë‹ˆë‹¤ë§Œ, ê±±ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ì¼ì´ ì•”ê¸°í•  í•„ìš”ëŠ” ì—†ê³ , í•µì‹¬ì ì¸ ê°œë…ë§Œ ìˆ™ì§€í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNZHb_6sAgR"
      },
      "source": [
        "### Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtGkxoMbr9UM"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/13.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFu9Rybr0sV"
      },
      "source": [
        "ë¨¼ì € LSTMì€ 3ê°€ì§€ ê²Œì´íŠ¸ë¥¼ ì´ìš©í•´ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ë§ê°í•˜ê³ , ê¸°ì–µí•  ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ìœ„ ê·¸ë¦¼ì—ì„œ ğœë¡œ í‘œê¸°ëœ ê²ƒì€ sigmoid í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ 3ê°œì˜ sigmoid í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³  ê°ê°ì€ \"ë§ê°\", \"ê¸°ì–µ\", \"ì¶œë ¥\"ì„ ì˜ë§ˆí•©ë‹ˆë‹¤. ì¦‰, LSTMì€ ì–´ë–¤ ì •ë³´ë¥¼ ìŠì–´ë²„ë¦¬ê³ , ì–´ë–¤ ì •ë³´ëŠ” ê¸°ì–µí•  ì§€ë¥¼ ì´ Gateë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ê° ê²Œì´íŠ¸ë³„ ì„¸ë¶€ ë‚´ìš©ì€ ì•„ë˜ì„œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsDpzIpMoI26"
      },
      "source": [
        "### Cell State\n",
        "\n",
        "ë¨¼ì € LSTMì€ ë‹¤ìŒ ì‹œì ì— cell stateì™€ hidden state 2ê°€ì§€ ê°’ì„ ì „ë‹¬í•©ë‹ˆë‹¤. ë¨¼ì € cell stateëŠ” ì´ì „ ì‹œì ìœ¼ë¡œë¶€í„° ìƒíƒœ ê°’ì„ ë°›ì•„ì™€ì„œ \"ë§ê°\"ê³¼ \"ê¸°ì–µ\" ê³¼ì •ì„ ê±°ì³ì„œ ë‹¤ìŒ ìƒíƒœë¡œ ì „ë‹¬ë˜ëŠ” ê°’ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E1xzDR2qXVQ"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/14.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF4acM44sx2p"
      },
      "source": [
        "### forget gate\n",
        "\n",
        "ë¨¼ì € ë§ê° ê²Œì´íŠ¸ì…ë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ ì‹œì ì˜ ì…ë ¥ê³¼ ì´ì „ ì‹œì ì˜ hidden stateë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ linear layerì™€ sigmoidë¥¼ í†µê³¼ì‹œì¼œì¤ë‹ˆë‹¤. sigmoidë¥¼ í†µê³¼í–ˆìœ¼ë‹ˆ ê°’ì´ 0ê³¼ 1 ì‚¬ì´ê°€ ë©ë‹ˆë‹¤. ì´ë¥¼ ì´ì „ ì‹œì ì˜ cell stateì— ê³±í•´ì£¼ë©´, ì–´ë–¤ ì •ë³´ëŠ” ìŠê³  ì–´ë–¤ ì •ë³´ëŠ” ë³´ì¡´í•  ì§€ ê²°ì •í•˜ëŠ” ë§ê°ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2R6DWJgtD0A"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/15.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNi7FTcptz8d"
      },
      "source": [
        "### input gate\n",
        "\n",
        "ê·¸ ë‹¤ìŒ cell stateì— í˜„ì¬ ì‹œì ì˜ ì…ë ¥ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” input gateì…ë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ ì‹œì ì˜ ê°’ ì¤‘ ì–´ë–¤ ê²ƒì„ cell stateì— ì¶”ê°€í•  ì§€ ê²Œì´íŠ¸ë¥¼ ê±°ì¹œ ë‹¤ìŒ, ê±¸ëŸ¬ë‚¸ ì •ë³´ë¥¼ cell stateì— ë”í•´ì¤ë‹ˆë‹¤. ì¦‰, cell stateì— í˜„ì¬ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ê³„ì‚°í•œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ê°€í•´ì£¼ëŠ” ì…ë ¥ì„ êµ¬í˜„í•˜ê²Œ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rah_DCPvt60W"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KJr9kqmp8lQ"
      },
      "source": [
        "### output gate & hidden state\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶œë ¥ ê²Œì´íŠ¸ì…ë‹ˆë‹¤. ì´ëŠ” ìƒˆë¡­ê²Œ êµ¬í•œ cell stateì™€ í˜„ì¬ ì‹œì ì˜ ì…ë ¥, ì´ì „ ì‹œì ì˜ hidden stateë¡œ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ hidden stateë¥¼ êµ¬í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë‚´ì£¼ê³ , ë‹¤ìŒ ì‹œì ìœ¼ë¡œ ì „ë‹¬í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10rYl2l24XcX"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/17.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AnPh_Em4v9m"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w487TaiNfrSX"
      },
      "source": [
        "## ì‹¤ìŠµ ì‚¬ì „ ì‘ì—…\n",
        "\n",
        "ì´ì œ LSTMì„ ì´ìš©í•´ì„œ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ë³´ê² ìŠµë‹ˆë‹¤. ë°ì´í„° ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , í† í¬ë‚˜ì´ì €ì™€ ë°ì´í„° ì…‹, ë°ì´í„° ë¡œë”ë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJje6_c8if8O"
      },
      "source": [
        "### ë°ì´í„° ì…‹ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wluJGzFfQsUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_LrsZApkHuv"
      },
      "source": [
        "### tokenizer ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnAHgVhbkLct",
        "outputId": "637052f4-b90e-47bd-d013-cbe824abcdc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /Users/user/miniconda3/lib/python3.10/site-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/user/miniconda3/lib/python3.10/site-packages (from tokenizers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.9.2)\n",
            "Requirement already satisfied: requests in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2022.12.7)\n",
            "\u001b[33mDEPRECATION: pytorch-lightning 1.8.3.post1 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: mecab-python 0.996-ko-0.9.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of mecab-python or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7YvhjjIQtWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHhDkqzNkTC7"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWN_gHkUkGQ1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, corpus_df, transform=None):\n",
        "        self.corpus_df = corpus_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.corpus_df.iloc[idx]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7R6WihKkaij"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomTextDataset(train_df)\n",
        "val_dataset = CustomTextDataset(val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7C2En_zs8i-"
      },
      "source": [
        "### DataLoader\n",
        "\n",
        "dataloader êµ¬í˜„ ì‹œì— ë°°ì¹˜ ë‚´ ê° ë¬¸ì¥ë³„ í† í° ê°œìˆ˜ë¥¼ ì§‘ê³„í•œ batch_lengthsë¥¼ ì¶”ê°€ë¡œ ë¦¬í„´í•´ì£¼ë„ë¡ í•©ë‹ˆë‹¤. ì´ëŠ” RNN í•™ìŠµ ì‹œì— pack_padded_sequenceë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•¨ì´ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp_y6g3JkcCd"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS = 256\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppR8whfbkpRL"
      },
      "outputs": [],
      "source": [
        "vocabs = tokenizer.get_vocab()\n",
        "pad_token = vocabs[\"[PAD]\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyDIXfBLkfy1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def _tokenize(text):\n",
        "    tokens = tokenizer.encode(text).ids\n",
        "    tokens = tokens[:MAX_TOKENS]\n",
        "    token_tensor = torch.tensor(tokens, dtype=torch.long)\n",
        "    return token_tensor\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_text = [x[0] for x in batch]\n",
        "    batch_label = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
        "    batch_tokens = [_tokenize(x) for x in batch_text]\n",
        "    batch_lengths = torch.tensor([len(x) for x in batch_tokens])\n",
        "    batch_padded = pad_sequence(batch_tokens, padding_value=pad_token)\n",
        "    return batch_padded, batch_label, batch_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwJufBpckhCz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkBbOftaky9M"
      },
      "outputs": [],
      "source": [
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Ffu7l0kuKQ",
        "outputId": "355e5f86-3ce8-461c-af27-726c7896558e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[1042, 1300, 6037,  ..., 5145, 2283, 9393],\n",
            "        [2705, 2660, 6429,  ..., 3265, 2669, 7752],\n",
            "        [2966, 7116,    7,  ..., 1107, 2636, 5110],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0]]), tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
            "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
            "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
            "        0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
            "        1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0]), tensor([34, 13, 56, 19, 11, 15,  5,  3,  9, 29,  5, 21,  7, 32, 16, 24, 10, 13,\n",
            "        10, 10,  9, 45, 14, 17,  4, 11,  4, 21,  6,  6,  2, 14,  7,  9,  7,  6,\n",
            "         6, 18, 10, 25, 14,  2, 15,  7, 11,  8, 56, 14, 42,  5, 42,  8,  3, 15,\n",
            "        12, 18, 26, 12, 14, 11, 21, 13, 12, 11, 17, 34,  8,  1, 10, 28, 21, 13,\n",
            "        33,  6, 23,  9, 23,  3, 16, 32,  2,  4, 65, 18,  6, 12, 12, 11,  9, 13,\n",
            "        11, 27, 17,  7,  7,  9, 15, 10, 15,  9,  9,  2, 50, 19,  6,  9,  5,  3,\n",
            "         3, 23, 12, 15, 10, 31,  3, 20, 14,  6, 58, 15, 13, 23, 31, 16, 22,  7,\n",
            "         5, 40]))\n"
          ]
        }
      ],
      "source": [
        "train_iterator = iter(train_dataloader)\n",
        "batch = next(train_iterator)\n",
        "print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_eoD_ik-0b"
      },
      "source": [
        "## LSTM ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "ì´ì œ RNNì„ ì´ìš©í•´ì„œ ë¬¸ì¥ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , ì´ë¥¼ í•™ìŠµì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤. LSTMë„ RNNê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ìƒíƒœ ê°’ì„ ì–‘ë°©í–¥ìœ¼ë¡œ íë¥´ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì—¬ëŸ¬ ì¸µì„ ìŒ“ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•œë²ˆ bidirectional=True, num_layers=2ë¡œ ì„¤ì •í•´ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì „ë°˜ì ì¸ êµ¬ì¡°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-JJvnxTBtl9"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/18.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LowjsglaoH"
      },
      "source": [
        "### ëª¨ë¸ ì‘ì„±"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljRB8kzdQvui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hxL5LPUpaHm"
      },
      "source": [
        "### í•™ìŠµ ì½”ë“œ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F2vNYfrpXHx"
      },
      "outputs": [],
      "source": [
        "def get_mean(metrics):\n",
        "    return round(sum(metrics) / len(metrics), 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_r0I1Hepda7"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def train_model(model):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    acc_list = []\n",
        "    for x_train, y_train, lengths in tqdm(train_dataloader):\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "\n",
        "        outputs = model(x_train, lengths)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        acc = ((y_train == pred).sum() / len(y_train)).item()\n",
        "        acc_list.append(acc)\n",
        "    return get_mean(loss_list), get_mean(acc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSvqySNbpesx"
      },
      "outputs": [],
      "source": [
        "def validate_model(model):\n",
        "    model.eval()\n",
        "    loss_list = []\n",
        "    acc_list = []\n",
        "    for x_val, y_val, lengths in tqdm(val_dataloader):\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(x_val, lengths)\n",
        "            loss = criterion(outputs, y_val)\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            pred = torch.argmax(outputs, dim=1)\n",
        "            acc = ((y_val == pred).sum() / len(y_val)).item()\n",
        "            acc_list.append(acc)\n",
        "    return get_mean(loss_list), get_mean(acc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOnvI5N-pgJA"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def train_validate_model(model):\n",
        "    logs = defaultdict(list)\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_model(model)\n",
        "        val_loss, val_acc = validate_model(model)\n",
        "        logs[\"train_loss\"].append(train_loss)\n",
        "        logs[\"train_acc\"].append(train_acc)\n",
        "        logs[\"val_loss\"].append(val_loss)\n",
        "        logs[\"val_acc\"].append(val_acc)\n",
        "        print(f\"epoch {epoch + 1} train - loss: {train_loss} acc: {train_acc} val - loss: {val_loss} acc: {val_acc}\")\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IwLAPPCpire"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_logs(logs):\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "    ax0 = fig.add_subplot(1, 2, 1)\n",
        "    ax1 = fig.add_subplot(1, 2, 2)\n",
        "    ax0.plot(logs[\"train_loss\"], label=\"train\")\n",
        "    ax0.plot(logs[\"val_loss\"], label=\"val\")\n",
        "    ax0.legend()\n",
        "    ax0.set_title(\"loss\")\n",
        "\n",
        "    ax1.plot(logs[\"train_acc\"], label=\"train\")\n",
        "    ax1.plot(logs[\"val_acc\"], label=\"val\")\n",
        "    ax1.legend()\n",
        "    ax1.set_title(\"accuracy\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zno3lRi3pmBz"
      },
      "source": [
        "### í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì…‹íŒ…"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OYkFRMGQzU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGkXmg0Fpp3C"
      },
      "source": [
        "### í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4wfUAlaQ0WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyq9ZZFd9OzP"
      },
      "source": [
        "## GRUë¥¼ ì´ìš©í•œ ë¬¸ì¥ ë¶„ë¥˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "052iwV467iWc"
      },
      "source": [
        "\n",
        "\n",
        "### GRU ê¸°ë³¸ êµ¬ì¡°\n",
        "Gated Recurrent Unitì˜ ì•½ìë¡œ, LSTMì˜ ì•½ì ì„ ë³´ì™„í•œ ëª¨ë¸ì…ë‹ˆë‹¤. LSTMì€ ë‹¤ìŒ ì…€ë¡œ cell stateì™€ hidden_state 2ê°€ì§€ ìƒíƒœ ê°’ì„ ë„˜ê²¨ì£¼ì—ˆìŠµë‹ˆë‹¤. GRUëŠ” ì´ê²ƒì´ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ ì œê±°í•˜ê³ , hidden_state í•˜ë‚˜ë§Œ ë„˜ê²¨ì£¼ëŠ” ê°„ì†Œí™” ëœ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "ê³„ì‚° ìˆ˜ì‹ì€ ëª¹ì‹œ ë³µì¡í•˜ì§€ë§Œ, ëª¨ë‘ ê¸°ì–µí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. LSTMì„ ê°„ì†Œí™” í•˜ì˜€ì§€ë§Œ ì„±ëŠ¥ì€ ë¹„ìŠ·í•˜ê±°ë‚˜ ì˜¤íˆë ¤ ë” ë›°ì–´ë‚œ ëª¨ë¸ì´ë¼ëŠ” ê²ƒë§Œ ì§šê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yCfpQ8V8y-Y"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/19.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkXNlM4r97GI"
      },
      "source": [
        "### GRU ëª¨ë¸ ì‘ì„± ë° í•™ìŠµ\n",
        "\n",
        "GRUëŠ” ë‹¤ìŒ ì…€ë¡œ hidden_state í•˜ë‚˜ë§Œ ë„˜ê²¨ì£¼ë©´ ë˜ë¯€ë¡œ, vanila RNNê³¼ ì½”ë“œ êµ¬í˜„ì´ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤. ê¸°ì¡´ RNNì„ GRUë¡œë§Œ ë°”ê¿”ì£¼ë©´ ë©ë‹ˆë‹¤. êµ¬ì¡°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECaxL1CFCM0q"
      },
      "source": [
        "![image](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/20.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yc3dlkYfQ17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYnWVOBM-c1k"
      },
      "source": [
        "GRUë„ ë§ˆì°¬ê°€ì§€ë¡œ bidirectional=True, num_layersëŠ” 2ë¡œ ì„¤ì •í•˜ì—¬ í•™ìŠµì‹œì¼œ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-irUie3Q27o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Sj193aODBJ"
      },
      "source": [
        "## ì •ë¦¬\n",
        "\n",
        "ì´ë²ˆ ì±•í„°ì—ì„œëŠ” ì¥ê¸° ê¸°ì–µì„ ì €ì¥í•  ìˆ˜ ìˆëŠ” LSTM ëª¨ë¸ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. íŠ¹íˆë‚˜ ê¸´ sequenceë¥¼ ë‹¤ë£° ë•Œì—ëŠ” vanila RNN ë³´ë‹¤ LSTM í˜¹ì€ GRUë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. êµ¬ì¡°ê°€ ë§ì´ ë³µì¡í–ˆì§€ë§Œ, ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì–´ë µì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë„ˆë¬´ ìˆ˜ì‹ í•˜ë‚˜í•˜ë‚˜ì— ë§¤ë‹¬ë¦¬ì§€ ë§ê³ , ì¥ê¸° ê¸°ì–µì„ ì €ì¥í•˜ê¸° ìœ„í•œ êµ¬ì¡°ë¼ëŠ” ì ë§Œ ê¸°ì–µí•˜ê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}