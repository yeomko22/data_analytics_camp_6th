{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeomko22/data_analytics_camp_6th/blob/main/week_12/deeplearning_nlp/ch_4_vanila_RNN_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOXnOpGpbShY"
      },
      "source": [
        "# ch 4. vanila RNN\n",
        "\n",
        "컴퓨터 비전 분야에서 CNN을 많이 사용했던 것 처럼, 자연어 처리 분야에서는 RNN이라는 신경망 구조를 많이 사용합니다. 근래에는 transformer로 많이 대체되긴 하였습니다만, 여전히 널리 사용되는 기법입니다. 이번 챕터에서는 RNN을 이용해서 텍스트 분류 모델을 만들어보면서, 개념을 익혀보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWXrSVE8f6VJ"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhBiBKxGbVC2"
      },
      "source": [
        "### RNN 기본 구조\n",
        "\n",
        "이전 챕터에서는 각 토큰 별 임베딩 벡터를 평균 낸 뒤, 이를 리니어 레이어에 통과시켜서 예측 결과를 냈습니다. 이 경우, 토큰이 등장하는 순서를 모델에 반영할 수 없습니다. 하지만 자연어는 토큰들이 등장하는 순서, 그리고 앞 뒤에 어느 토큰이 오는지가 중요한 의미를 갖습니다. 이를 반영할 수 있는 모델이 recurrent neural network입니다. 먼저 구조를 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzPUJr0wbW3J"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAzBza81basf"
      },
      "source": [
        "먼저 RNN은 자연어 데이터를 시계열 데이터로 봅니다. 그리고 t번째 토큰은 Xt로 표현합니다. ht는 t 시점의 입력 값에 대한 모델의 예측값이 됩니다. 그리고 중간에 자기 자신으로 되돌아가는 화살표가 보이는데 이 부분이 RNN의 핵심입니다. t 시점에 예측값을 계산하기 위해 계산한 상태 값을 다음 시점의 예측값을 내는데 다시 사용한다는 의미입니다. 이를 모든 시점에 대해서 전개하면 아래와 같은 모습이 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoiFo_eFdwCY"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJVfjax8d-eG"
      },
      "source": [
        " 문장 하나는 t개의 토큰이 순서대로 등장하는 시퀀스입니다. 0번째 토큰부터 순서대로 모델에 넣어주면, 해당 시점에 예측 값과 hidden state가 구해집니다. 이제 1번째 토큰을 입력으로 넣으면 0번째 토큰으로 계산한 hidden state를 전달받아서 이를 반영하여 새로운 hidden state와 예측 값을 계산하게 됩니다. 이를 마지막 입력 토큰까지 반복하여 최종 예측 결과값을 내려주는 것이 기본적인 RNN의 구조입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_J-CZmYf9SG"
      },
      "source": [
        "### RNN 수식 표현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ra1hwTigZBb"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVnf1Yrgz1y"
      },
      "source": [
        "RNN 레이어는 크게 3 종류의 weight를 학습하게 됩니다. 현재 시점 토큰의 임베딩에 곱해주는 Wx, 이전 hidden state에 곱해주는 Wh, 예측 값을 내기위해 현재 hidden state에 곱해주는 Wy입니다. 수식으로 표현하면 아래와 같습니다.\n",
        "\n",
        "$$h_{t}=tanh(W_{x}x_{t}+W_{h}h_{t-1}+b)$$\n",
        "\n",
        "$$y_{t}=f(W_{y}h_{t}+b)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIwdEI0Mhbsr"
      },
      "source": [
        "### tanh\n",
        "tanh라고 표기된 함수는 hypterbolic tangent라고 부르며, RNN 계열에서 많이 사용합니다. 이를 시각화해보면 sigmoid 함수와 상당히 유사합니다만, 출력 값의 범위가 -1과 1 사이가 됩니다.\n",
        "\n",
        "$$tanh(x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "y-LeBs1ohq5Y",
        "outputId": "00047b8b-f90b-43c5-bcca-4753547b4104"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAE8CAYAAAC1qXpoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzNElEQVR4nO3deXwU9f3H8dfuJtkkQCBATrnCIeE+giCXgASCWiyt0npUgSKoBQuGelCtiBfWimCVn6CtoKjVVlsrSNGIHCqnXHLfN+QgkIuQZLM7vz9CVnKAJGQz2ez7+XjEzczOTD7fr5u8me9cFsMwDERERMTNanYBIiIiNY3CUUREpBSFo4iISCkKRxERkVIUjiIiIqUoHEVEREpROIqIiJSicBQRESlF4SgiIlKKwlGkGi1YsACLxcL3339f6W0sXbqUrl27EhgYiMViISMjo+oKrEIWi4Wnn37a7DJEKkXhKD5v9erVPP300zU2ZC6Wnp7Or371K4KCgpgzZw4LFy6kTp06ptWzZMkSBaDUSn5mFyBittWrVzN9+nRGjx5NgwYNzC7nsjZs2EB2djbPPvss8fHxZpfDkiVLmDNnTrkBef78efz89CdGvJM+uSJeJDU1FaDGhzhAYGCg2SWIVJqGVcWnPf300zzyyCMAxMTEYLFYsFgsHD58GID58+dz4403Eh4ejt1up3379rzxxhtlttOiRQt+9rOf8e2339KzZ08CAwNp2bIl7777brk/Nz8/n8TERMLCwqhTpw6/+MUvSEtLu2ytAwcOZNSoUQBcd911WCwWRo8e7f75xd+XXmfgwIHu6RUrVmCxWPjnP//J888/T5MmTQgMDGTw4MHs37+/zPrr1q3j5ptvJjQ0lDp16tC5c2deffVVAEaPHs2cOXMA3P1msVjc65Z3zHHz5s3cdNNNhISEULduXQYPHszatWtLLFN8XPa7776rcB+JVBXtOYpP++Uvf8nevXv5xz/+waxZs2jcuDEAYWFhALzxxht06NCBW2+9FT8/PxYtWsTvfvc7XC4XEyZMKLGt/fv3c/vttzN27FhGjRrF22+/zejRo4mLi6NDhw4lln3ooYcIDQ1l2rRpHD58mNmzZzNx4kQ++uijS9b6xBNP0LZtW958802eeeYZYmJiaNWqVaXa/eKLL2K1WvnDH/5AZmYmL730EnfffTfr1q1zL5OUlMTPfvYzoqKimDRpEpGRkezatYvFixczadIk7r//fk6ePElSUhILFy78yZ+5Y8cO+vfvT0hICI8++ij+/v7MmzePgQMHsnLlSnr16nXVfSRSZQwRH/eXv/zFAIxDhw6VeS83N7fMvISEBKNly5Yl5jVv3twAjFWrVrnnpaamGna73ZgyZYp73vz58w3AiI+PN1wul3v+ww8/bNhsNiMjI+OytRavv2HDhjI/f9SoUWWWHzBggDFgwAD39PLlyw3AaNeunZGfn++e/+qrrxqAsW3bNsMwDKOwsNCIiYkxmjdvbpw9e7bENi+ue8KECcal/owAxrRp09zTI0aMMAICAowDBw645508edKoV6+eccMNN5RpY2X7SKQqaFhV5DKCgoLc32dmZnL69GkGDBjAwYMHyczMLLFs+/bt6d+/v3s6LCyMtm3bcvDgwTLbHT9+fIkhyP79++N0Ojly5IgHWlHWmDFjCAgIKPHzAXetmzdv5tChQ0yePLnM8c2L675STqeTL7/8khEjRtCyZUv3/KioKO666y6+/fZbsrKySqxjdh+Jb1M4ilzGd999R3x8PHXq1KFBgwaEhYXxxz/+EaBMODZr1qzM+qGhoZw9e7bM/NLLhoaGApS7rCf81M8/cOAAAB07dqySn5eWlkZubi5t27Yt8167du1wuVwcO3asQjWKeJKOOYpcwoEDBxg8eDCxsbG88sorNG3alICAAJYsWcKsWbNwuVwllrfZbOVuxzCMMvMqsuyVuNTenNPpLPdnVfXP9wRvqFFqL4Wj+LxLBcuiRYvIz8/ns88+K7EXs3z58uoq7YqFhoaWexODI0eOlBjGvFLFJ/ps3779stdTXukQa1hYGMHBwezZs6fMe7t378ZqtdK0adMK1yniKRpWFZ9XfIeZ0uFSvOdy8Z5KZmYm8+fPr7barlSrVq1Yu3YtBQUF7nmLFy8uM1R5pbp3705MTAyzZ88u0y8X98el+q40m83G0KFD+e9//+u+TAYgJSWFDz74gH79+hESElKpWkU8QXuO4vPi4uKAoksl7rjjDvz9/Rk+fDhDhw4lICCA4cOHc//995OTk8Nbb71FeHg4p06dMrnqku677z4+/vhjhg0bxq9+9SsOHDjAe++9V+lLPaxWK2+88QbDhw+na9eujBkzhqioKHbv3s2OHTv44osvgB/77ve//z0JCQnYbDbuuOOOcrf53HPPkZSURL9+/fjd736Hn58f8+bNIz8/n5deeqlyDRfxEO05is+77rrrePbZZ9m6dSujR4/mzjvvJC0tjbZt2/Lxxx9jsVj4wx/+wNy5cxk/fjyTJk0yu+QyEhISmDlzJnv37mXy5MmsWbOGxYsX06RJk6va5vLly7n22muZOXMmiYmJLFu2jOHDh7uX+eUvf8lDDz3E0qVLueeee7jzzjsvub0OHTrwzTff0LFjR2bMmMH06dNp3rw5y5cvL3ONo4jZLIaObouIiJSgPUcREZFSFI4iIiKlKBxFRERKUTiKiIiUonAUEREpReEoIiJSSq27CYDL5eLkyZPUq1evUk8PEBGR2sEwDLKzs4mOjsZqrdi+YK0Lx5MnT+oejSIi4nbs2LEK3xCj1oVjvXr1ADh06BANGzY0uRpzOBwOvvzyS4YOHYq/v7/Z5ZjC1/vA19sP6gNfbz/AmTNniImJcedCRdS6cCweSq1Xr57P3sjY4XAQHBxMSEiIz/5S+Hof+Hr7QX3g6+2Hoj6Ayj2gWyfkiIiIlKJwFBERKUXhKCIiUopHw3HVqlUMHz6c6OhoLBYLn3766U+us2LFCrp3747dbqd169YsWLDAkyWKiIiU4dFwPHfuHF26dGHOnDlXtPyhQ4e45ZZbGDRoEFu2bGHy5Mncd9997gerioiIVAePnq160003cdNNN13x8nPnziUmJoaZM2cC0K5dO7799ltmzZpFQkKCp8oUEREpoUZdyrFmzRri4+NLzEtISGDy5MmXXCc/P5/8/Hz3dFZWFlB0Cm/xaby+prjdvtp+UB/4evuhevrA5TLIdTg5X+Akt8DJeUfRV77DRV5h0WuB00V+oYuCQhcOpwuH08DhdFHoNHC4il6dLoNC14+vLuPC64V5LsPAZYDLMDAuvBbPM9yvRd8bXHjfZXDmjI13T6zDYrEUvc+Py8CFdYqnSr643y+aZ7i/L8/F711msUuvdCWLV2jpIo7zOZVYq0iNCsfk5GQiIiJKzIuIiCArK4vz588TFBRUZp0ZM2Ywffr0MvOXL19OcHCwx2r1BklJSWaXYDpf7wNfbz9ceR+4DMh2QFYBZDosZBdATiHkOCycK4TcQsgttHC+EM47Ic8JBU4wqMm3qbRAdqbZRZjGlZ9b6XVrVDhWxtSpU0lMTHRPZ2Vl0bRpUwYNGkSjRo1MrMw8DoeDpKQkhgwZ4tMX//pyH/h6+6H8PsgvdHEw7RwHT5/jSHouR87kcuzseU5lnCc5K59CV2X2T8BigWB/G0EBNgL9rNj9bQT6W7H72bD7WQnwsxJgK/ryt1nw97PiZ7XgZ7Pib7XgZ7Ngs1qwWYpe/awWrNai762W4lewWoqmLe7vcX9vsViw8OO00+lk27Yf6NK5M35+fu73LFguvBYX/+NF8paL2nPR2xe101Lu/PJnFM++sn88eOJW2JkZZxkxu3Lr1qhwjIyMJCUlpcS8lJQUQkJCyt1rBLDb7djt9jLz/f39ffaPQjH1gfrAl9ufW1DIgSw4tf4E209mszs5m0Onz+G8TADarBYa1w0grJ6dsLp2Gte107BOAKF1AmgQ5E/9C18hQf7UtftRx+5HXbsfgf7WGvegA4fDgd/Jrdzc5Rqf/Qykp1e+3TUqHHv37s2SJUtKzEtKSqJ3794mVSQi3iLP4WT9oTOsOZjOmgPpbDuRidPlBzv2llguJNCPNhH1aNGoDi0aBdOsUTBNQoOIbhBEWF07fjZd/i0eDsecnBz279/vnj506BBbtmyhYcOGNGvWjKlTp3LixAneffddAB544AFef/11Hn30UX7729/y9ddf889//pPPP//ck2WKiJfKzHWQtCuFpJ3JfLPvNLkFzhLv1w8w6Nkqgq7NQukQHUJsZAgRIfYat5cnNY9Hw/H7779n0KBB7uniY4OjRo1iwYIFnDp1iqNHj7rfj4mJ4fPPP+fhhx/m1VdfpUmTJvztb3/TZRwi4uZwuli5J41PNh1n2a5UCpwu93uRIYH0bd2Y3q0acV2zELasXs7NN3f12WFFqTyPhuPAgQMxLnO6bnl3vxk4cCCbN2/2YFUi4o0ycgt4f91R3ll9mNTsHy/fio2sx9AOkQxtH0GH6BD3XqHD4WCLSbWK96tRxxxFREpLycrj/5bv55/fH+e8o2jYtHHdAH7e9Rpu696E9tG++Wg68SyFo4jUSJnnHcxbeYC3vztEnqNo6LRdVAjj+sfws87RBPjpxBnxHIWjiNQoLpfBhxuO8dIXu8nILbq7TVzzUBKHXEufVo10Mo1UC4WjiNQYh06f4/FPfmDdoTMAtAmvy6PDYolvF65QlGqlcBQR0xmGwfzvDvPnpbvJL3QR5G/jDwltGdW7ua47FFMoHEXEVNl5Dh775AeWbEsGoH+bxrzwi040bejb90YWcykcRcQ0u5OzePC9TRw6fQ5/m4Unbm7HqD4tNIQqplM4iogpvt13mvsXfs+5AifR9QN5/e7udG8WanZZIoDCUURMsPiHkzz80RYcToPeLRsx5+7uNKwTYHZZIm4KRxGpVgvXHuGp/27HMODmTpHM+nVX7H42s8sSKUHhKCLV5r21R/jTp9sB+M31zZh+a0dsVh1flJpH4Sgi1eKzrSf503+LgvHBga14NKGtTryRGksXEImIx63Yk0riR1swDLjn+uYKRqnxFI4i4lFbj2XwwHsbKXQZDO8SzfRbOygYpcZTOIqIx5zOyeeB9zaS53Ax4NowZo7sglXHGMULKBxFxCMcThcT3t/Eqcw8WoXV4fW7uulJGuI19EkVEY948X+7WXfoDHXtfsy7pwf1Av3NLknkiikcRaTKfbb1JH//9hAAL4/sQuvwuiZXJFIxCkcRqVKnMs/zxH+2AUWXbAzrGGlyRSIVp3AUkSpjGAaPfbKN7LxCujSpz5Qh15pdkkilKBxFpMr8Y/0xVu1Nw+5nZeavuupZjOK19MkVkSpxND2X5z7fCcAjCW11nFG8msJRRK5a0XDqD+QWOOkZ05Df9o0xuySRq6JwFJGrtviHU6w5mE6gv5WXb9eF/uL9FI4iclVyCwp5YckuAH43sDXNGgWbXJHI1VM4ishV+b/lBziVmUeT0CDG39DS7HJEqoTCUUQq7Uj6Od5cdRCAP/2sPYH+emix1A4KRxGptGcX76LA6aJ/m8YMbR9hdjkiVUbhKCKVsvZgOl/tSsHPamHa8PZ6DJXUKgpHEakwwzB45cu9ANzRsymtw+uZXJFI1VI4ikiFfbPvNOsPn8HuZ+WhG9uYXY5IlVM4ikiFGIbBzC/3AHDP9c2JCAk0uSKRqqdwFJEK+WpXKluPZxIcYOOBga3MLkfEIxSOInLFXK4f9xrH9G1B47p2kysS8QyFo4hcsS93JrM7OZt6gX6M76+9Rqm9FI4ickUMw2DuyqIL/kf3aUH9YH+TKxLxHIWjiFyRDYfPsuVYBnY/K6P6tDC7HBGPUjiKyBV5c9UBAG6La6JjjVLrKRxF5CftT83mq12pWCxwXz89q1FqP4WjiPyk4puLD2kXQcuwuiZXI+J5CkcRuazUrDw+3XwSgPsH6JFU4hsUjiJyWe+sOUyB00Vc81Dimjc0uxyRalEt4ThnzhxatGhBYGAgvXr1Yv369ZdcdsGCBVgslhJfgYG6PZWIGQoKXXy04RgAY3WsUXyIx8Pxo48+IjExkWnTprFp0ya6dOlCQkICqampl1wnJCSEU6dOub+OHDni6TJFpBxLdyRzOqeA8Hp2huh5jeJDPB6Or7zyCuPGjWPMmDG0b9+euXPnEhwczNtvv33JdSwWC5GRke6viAj9UoqY4b21Rf8wvaNnM/xtOgojvsPPkxsvKChg48aNTJ061T3ParUSHx/PmjVrLrleTk4OzZs3x+Vy0b17d1544QU6dOhQ7rL5+fnk5+e7p7OysgBwOBw4HI4qaol3KW63r7Yf1AdV0f59KTmsP3QGm9XC7d2ivK4v9Rnw7fbD1bXdo+F4+vRpnE5nmT2/iIgIdu/eXe46bdu25e2336Zz585kZmby8ssv06dPH3bs2EGTJk3KLD9jxgymT59eZv7y5csJDg6umoZ4qaSkJLNLMJ2v98HVtP/jQ1bASvv6TjZ/9zWbq66saqXPgO+2Pzc3t9LrejQcK6N379707t3bPd2nTx/atWvHvHnzePbZZ8ssP3XqVBITE93TWVlZNG3alEGDBtGoUaNqqbmmcTgcJCUlMWTIEPz9ffP+l77eB1fb/nP5hTzxl1VAIQ/f2oP+rRtXfZEeps+Ab7cfID09vdLrejQcGzdujM1mIyUlpcT8lJQUIiMjr2gb/v7+dOvWjf3795f7vt1ux24veysrf39/n/1AFFMfqA8q2/7/bT5FTn4hzRsFM7BtJFarxQPVVQ99Bny3/VfTbo8eYQ8ICCAuLo5ly5a557lcLpYtW1Zi7/BynE4n27ZtIyoqylNlikgpH6w7CsDdvZp5dTCKVJbHh1UTExMZNWoUPXr0oGfPnsyePZtz584xZswYAO69916uueYaZsyYAcAzzzzD9ddfT+vWrcnIyOAvf/kLR44c4b777vN0qSIC7EnOZtuJTPxtFm7rXvY4v4gv8Hg4/vrXvyYtLY2nnnqK5ORkunbtytKlS90n6Rw9ehSr9ccd2LNnzzJu3DiSk5MJDQ0lLi6O1atX0759e0+XKiLAJ5uOA3BjbDiN9PQN8VHVckLOxIkTmThxYrnvrVixosT0rFmzmDVrVjVUJSKlFTpd/HvTCQBuj2tqcjUi5tFVvSLitmpfGqdz8mlUJ4CBbcPMLkfENApHEXH7eGPRkOqIbtfojjji0/TpFxEAMnIL+Gpn0T2PdSKO+DqFo4gAsGjrSQqcLtpHhdA+OsTsckRMpXAUEeDHIdXb47TXKKJwFBEOpOWw9XgmflYLP+8abXY5IqZTOIoIn205CUD/No11baMICkcRn2cYBou2FoXjrdprFAEUjiI+b8fJLA6ePofdz8qQ9lf2QACR2k7hKOLjivcaB7cLp669xj3FTsQUCkcRH+ZyXTSk2kVDqiLFFI4iPmzj0bOczMyjrt2PgW3DzS5HpMZQOIr4sOKzVId2iCDQ32ZyNSI1h8JRxEcVOl0s2XYK0JCqSGkKRxEfteZgOunnCmhYJ4C+rRubXY5IjaJwFPFRS7YlA5DQIVJP4BApRb8RIj6o0Oniyx1F4XhzJ13bKFKawlHEB60/fIb0cwU0CPbn+paNzC5HpMZROIr4oP9dGFId2j5CQ6oi5dBvhYiPcbkMll4YUr2pU5TJ1YjUTApHER+z8ehZ0rLzqRfoR99WOktVpDwKRxEfU3xt45B2EQT46U+ASHn0myHiQ1wug6XbNaQq8lMUjiI+ZMvxDE5l5lEnwEb/NhpSFbkUhaOIDynea7yxne6lKnI5CkcRH2EYBl9cOEt1WAdd+C9yOQpHER+xNyWHI+m5BPhZGdA2zOxyRGo0haOIjyi+XVy/1o2pa/czuRqRmk3hKOIjvthZfKPxCJMrEan5FI4iPuBExnm2n8jCaoH4dgpHkZ+icBTxAcVDqj2aN6RRXbvJ1YjUfApHER9QfJbqUA2pilwRhaNILXf2XAHrD50Bih5sLCI/TeEoUst9tSsFlwHtokJo2jDY7HJEvILCUaSW+3JnCqCzVEUqQuEoUoudL3Dyzb40AIa0VziKXCmFo0gttvpAOnkOF9c0CKJ9VIjZ5Yh4DYWjSC321e4f9xotFovJ1Yh4D4WjSC3lMuDrPamAhlRFKkrhKFJLHc6GM+cchAT60TOmodnliHgVhaNILbXtbNGv96DYcPxt+lUXqYhq+Y2ZM2cOLVq0IDAwkF69erF+/frLLv+vf/2L2NhYAgMD6dSpE0uWLKmOMkVqle1nio4xakhVpOI8Ho4fffQRiYmJTJs2jU2bNtGlSxcSEhJITU0td/nVq1dz5513MnbsWDZv3syIESMYMWIE27dv93SpIrXGgbRzpOZZ8LdZGHCtnt0oUlEeD8dXXnmFcePGMWbMGNq3b8/cuXMJDg7m7bffLnf5V199lWHDhvHII4/Qrl07nn32Wbp3787rr7/u6VJFao2vdhX94/P6mIbUC/Q3uRoR7+PRJ54WFBSwceNGpk6d6p5ntVqJj49nzZo15a6zZs0aEhMTS8xLSEjg008/LXf5/Px88vPz3dNZWVkAOBwOHA7HVbbAOxW321fbD+qDr3YV3RVn0LWNfLYPfP0z4Ovth6tru0fD8fTp0zidTiIiSh7ziIiIYPfu3eWuk5ycXO7yycnJ5S4/Y8YMpk+fXmb+8uXLCQ727ftIJiUlmV2C6XyxD7IKYOtxG2DBlryTJUt2ml2SqXzxM3AxX25/bm5updf1aDhWh6lTp5bY08zKyqJp06YMGjSIRo0amViZeRwOB0lJSQwZMgR/f98cUvPlPvjn98cxNu6kaR2DkT/zvfYX8+XPAKj9AOnp6ZVe16Ph2LhxY2w2GykpKSXmp6SkEBlZ/qNzIiMjK7S83W7Hbi/78FZ/f3+f/UAUUx/4Zh98vec0AJ0aunyy/aX5eh/4cvuvpt0ePSEnICCAuLg4li1b5p7ncrlYtmwZvXv3Lned3r17l1geioYFLrW8iPwot6CQb/dfCMdQw+RqRLyXx4dVExMTGTVqFD169KBnz57Mnj2bc+fOMWbMGADuvfderrnmGmbMmAHApEmTGDBgADNnzuSWW27hww8/5Pvvv+fNN9/0dKkiXm/V3tPkF7poEhpEVHC22eWIeC2Ph+Ovf/1r0tLSeOqpp0hOTqZr164sXbrUfdLN0aNHsVp/3IHt06cPH3zwAU8++SR//OMfadOmDZ9++ikdO3b0dKkiXi/pwrMb42PDsKBwFKmsajkhZ+LEiUycOLHc91asWFFm3siRIxk5cqSHqxKpXQqdLr7efSEc24WTvuugyRWJeC/dcFGklth45Cxncx00CPYnrlkDs8sR8WoKR5FaonhI9ca24fjpRuMiV0W/QSK1gGEYJF24K45uNC5y9RSOIrXAvtQcjqTnEuBn5QbdaFzkqikcRWqBL3cU3V6xX+vG1LF7/Y2vREyncBSpBb7YUTSkOlRDqiJVQuEo4uVOZpxn24lMrBaIVziKVAmFo4iXKx5S7dG8IY3rlr3PsIhUnMJRxMt9eeESjqEdtNcoUlUUjiJe7Oy5AtYdOgNAQofyn1wjIhWncBTxYst2p+J0GbSLCqFpQ99+uLdIVVI4inix4uONOktVpGopHEW81PkCJ6v2pQEaUhWpagpHES+1cm8aeY6iZze2i6pndjkitYrCUcRLLd1+Cijaa7RYLCZXI1K7KBxFvFB+oZNlu1IBuLlTlMnViNQ+CkcRL/Td/tNk5xcSEWKnW9MGZpcjUusoHEW80JJtRWep3tQxCqtVQ6oiVU3hKOJlCgpd7ks4buqos1RFPEHhKOJl1hxMJyuvkMZ17fRo0dDsckRqJYWjiJf537bis1QjsGlIVcQjFI4iXqTQ6eKLC0OqOktVxHMUjiJeZN2hM5zNdRAa7E+vGA2piniKwlHEi3x+YUh1aPtI/Gz69RXxFP12iXgJh9PlPt54S2cNqYp4ksJRxEt8u/80Z3MdNKoTQJ9WjcwuR6RWUziKeIlFW08CRSfiaEhVxLP0GybiBfIcTr7ckQLArV2jTa5GpPZTOIp4geW7U8nJLyS6fiBxzULNLkek1lM4iniBzy4MqQ7vEq17qYpUA4WjSA2Xnedg2e6ix1MN76IhVZHqoHAUqeG+3JFCQaGLlmF16BAdYnY5Ij5B4ShSwxUPqd7aJRqLRUOqItVB4ShSg6Vm5fHt/tNAUTiKSPVQOIrUYJ9uOYHTZdC9WQNahtU1uxwRn6FwFKmhDMPg443HAbg9rqnJ1Yj4FoWjSA21/UQWe1NysPtZdS9VkWqmcBSpoT7eeAyAoR0iqR/kb3I1Ir5F4ShSA+UXOvnvhbNUb49rYnI1Ir5H4ShSA329K5WMXAcRIXb6tW5sdjkiPkfhKFIDFZ+I88vuTbDpdnEi1U7hKFLDpGblsWJvGgC3ddeQqogZPBqOZ86c4e677yYkJIQGDRowduxYcnJyLrvOwIEDsVgsJb4eeOABT5YpUqN8uOEYTpdBXPNQWofr2kYRM/h5cuN33303p06dIikpCYfDwZgxYxg/fjwffPDBZdcbN24czzzzjHs6ODjYk2WK1BiFThf/WH8UgN9c38zkakR8l8fCcdeuXSxdupQNGzbQo0cPAF577TVuvvlmXn75ZaKjL30rrODgYCIjIz1VmkiN9fXuVE5l5hEa7M9NHXVto4hZPBaOa9asoUGDBu5gBIiPj8dqtbJu3Tp+8YtfXHLd999/n/fee4/IyEiGDx/On/70p0vuPebn55Ofn++ezsrKAsDhcOBwOKqoNd6luN2+2n7w3j5YuOYwALd1vwYbLhwOV6W2463tr0q+3ge+3n64urZ7LByTk5MJDw8v+cP8/GjYsCHJycmXXO+uu+6iefPmREdH88MPP/DYY4+xZ88e/v3vf5e7/IwZM5g+fXqZ+cuXL/f54dikpCSzSzCdN/XB6Tz4Zr8fFgyizu1nyZL9V71Nb2q/p/h6H/hy+3Nzcyu9boXD8fHHH+fPf/7zZZfZtWtXpQsaP368+/tOnToRFRXF4MGDOXDgAK1atSqz/NSpU0lMTHRPZ2Vl0bRpUwYNGkSjRo0qXYc3czgcJCUlMWTIEPz9ffPOKt7YBy8u3QMcoX+bxtz7y7ir2pY3tr+q+Xof+Hr7AdLT0yu9boXDccqUKYwePfqyy7Rs2ZLIyEhSU1NLzC8sLOTMmTMVOp7Yq1cvAPbv319uONrtdux2e5n5/v7+PvuBKKY+8J4+yHM4+ffmojvi3NM7pspq9pb2e5Kv94Evt/9q2l3hcAwLCyMsLOwnl+vduzcZGRls3LiRuLiifwV//fXXuFwud+BdiS1btgAQFaWTE6T2WrT1JGdzHUTXD+TG2PCfXkFEPMpj1zm2a9eOYcOGMW7cONavX893333HxIkTueOOO9xnqp44cYLY2FjWr18PwIEDB3j22WfZuHEjhw8f5rPPPuPee+/lhhtuoHPnzp4qVcRUhmHw1jcHAbindwvdEUekBvDoTQDef/99YmNjGTx4MDfffDP9+vXjzTffdL/vcDjYs2eP+6BpQEAAX331FUOHDiU2NpYpU6Zw2223sWjRIk+WKWKqFXvS2JuSQ50AG3f10rWNIjWBR28C0LBhw8te8N+iRQsMw3BPN23alJUrV3qyJJEaZ96qAwDc2bOZHk0lUkPo3qoiJvrheAZrD57Bz2rht/1izC5HRC5QOIqYaN6qomONw7tEE90gyORqRKSYwlHEJEfTc/nftlMAjOvf0uRqRORiCkcRk8xbdQCXAf3bNKZ9dIjZ5YjIRRSOIiY4diaXf35/DICJg1qbXI2IlKZwFDHBX5ftw+E06N+mMb1a+uZtDkVqMoWjSDU7mJbDJ5uOA5A45FqTqxGR8igcRarZ7K/24TIgvl043ZqFml2OiJRD4ShSjXYnZ7Hoh6IbjD+svUaRGkvhKFKNXv5iL4YBt3SKokN0fbPLEZFLUDiKVJNVe9P4alcKNquFh4e0MbscEbkMhaNINSgodPH0oh0AjOrdgtbh9UyuSEQuR+EoUg3eWX2Yg2nnaFw3gMnaaxSp8RSOIh6WmpXHq8v2AfDosFhCAvXkDZGaTuEo4mEvLt1NTn4hXZo24PbuTcwuR0SugMJRxINW7k3j35tOADD91g5YrRaTKxKRK6FwFPGQzPMOHvv4BwBG92lB16YNzC1IRK6YwlHEQ6Yv2kFyVh4xjevw2LBYs8sRkQpQOIp4wBc7kvn3phNYLfDyyM4EBdjMLklEKkDhKFLF0rLzeeI/2wAYf0Mr4po3NLkiEakohaNIFXI4XUz4YBOncwpoG1FPd8IR8VIKR5EqNGPJbtYfOkNdux//95vu2P00nCrijRSOIlXkv1tO8PZ3hwCY+asutAqra3JFIlJZCkeRKrD9RCaPfVJ02cbEQa1J6BBpckUicjUUjiJX6WBaDqPeXk+ew8WAa8P0nEaRWkDhKHIVTmWe556/ryf9XAEdokN47a5u2HQXHBGvp3AUqaQz5wq45+/rOZFxnpaN6/DOb3vqpuIitYTCUaQSUrLyuOuttexPzSGqfiDvju1J47p2s8sSkSriZ3YBIt7mYFoO9769nuNnzxNWz87CsT1pEhpsdlkiUoUUjiIVsO14JqPnFx1jbNEomIVje9G0oYJRpLZROIpcoY83HufJT7eR53DR8ZoQFozRUKpIbaVwFPkJeQ4n0xft4B/rjwEw4NowXr+rG/V08o1IraVwFLmMnSez+MO/trLzVBYWC0wefC0P3dhaDy0WqeUUjiLlyHM4ee3rfcxbeZBCl0FosD+v3tGNG64NM7s0EakGCkeRixiGwde7U3n+810cPH0OgJs6RjL91g6EhwSaXJ2IVBeFo8gFG4+c4cX/7WbD4bMAhNWz8+zPOzKso+6TKuJrFI7i0wzDYOXeNP72zSG+3X8aALuflTF9Y3hwYCvqB+mkGxFfpHAUn5SRW8CirSd5d80R9qXmAGCzWhgZ14RJ8W2Iqh9kcoUiYiaFo/iM8wVOVu1L49PNJ1i2K5UCpwuAunY/7riuKaP6tNAF/SICKBylFjMMOHImlw1HMlm2K4Vv9p0mv9Dlfr99VAi3xTVhZI8mumG4iJSgcJRao6DQxZ7kbLYcz2DT4XSW77SRsfbbEss0CQ1iWIdIbotrQruoEJMqFZGazmPh+Pzzz/P555+zZcsWAgICyMjI+Ml1DMNg2rRpvPXWW2RkZNC3b1/eeOMN2rRp46kyxQvlFzo5duY8R9LPsT81hz0p2exJzmZfag4FF+0ZggV/m4UuTRpww7VhDGkfQWxkPSwWXcAvIpfnsXAsKChg5MiR9O7dm7///e9XtM5LL73EX//6V9555x1iYmL405/+REJCAjt37iQwUNeY1XZOl0FGbgFncwtIzykgNTuftOx8UrLzOJWRx6nM85zMyONk5nkMo/xt1A/yp3OT+nSKDsFI3ccDtw+hfh2dXCMiFeOxcJw+fToACxYsuKLlDcNg9uzZPPnkk/z85z8H4N133yUiIoJPP/2UO+64w1OlSimGYeB0GRS6DFzGhdcL04VOA4fTRaGr6LXoq+j7gsKir/xCJ/mFLvIcTvIcLs47nOQWODlfUEhugZNz+YXk5DvJyXeQnVdI5nkHWecdZOcXXjL0SqsTYKN5ozrEhNUhNqIe10bWIzayHs0aBmOxWHA4HCxZspfgAB05EJGKqzF/OQ4dOkRycjLx8fHuefXr16dXr16sWbPmkuGYn59Pfn6+ezorKwuAkfPW4h9Ut1K1XOkf6BLrUP5KpbdlXPI9o8x8o5zlDAwM48J7F94wLnxb9Fr0fl6ejee2rXC/77ow3zCKvncZRdtyuYq+L57ndFWi8VWsfpAfocEBhNWzE1Y3gMZ17UTVDyS6fiBR9QNp2jCIRnUCyh0eLSwsBMDhcJR49TW+3n5QH/h6++Hq2l5jwjE5ORmAiIiIEvMjIiLc75VnxowZ7r3Ui+1Py8Xq008TsoCjoMq3arUY2CyU+PKz/vi9v7Vo2s9iEGArmva3QoAV7Fbwt0GgzSDQBnYbBNkg2M8gyK/o+zr+YLMUAnklf3BW0depY3CqAvUmJSVVYeu9j6+3H9QHvtz+3NzcSq9boXB8/PHH+fOf/3zZZXbt2kVsbGylC6qoqVOnkpiY6J7OysqiadOmvP7rjtRvEFrlP+9y53JYKP/Ny65z0XsXr196HQu495Qs7v/8ON9yYR0LFpzOQtatW8v111+Pv58/FgtYLT8uZ7VYsFqLlrVaL0xbLFgtRRfCWywWbBYLNqsFmxVsFgt+Nqt7G97A4XCQlJTEkCFD8Pf3vcs0fL39oD7w9fYDpKenV3rdCoXjlClTGD169GWXadmyZaUKiYwsun9lSkoKUVFR7vkpKSl07dr1kuvZ7Xbs9rK7iH3bhNOoUaNK1eLtHA4HJ7ZD56YNffaXopi/v79P94Gvtx/UB77c/qtpd4XCMSwsjLAwzzyyJyYmhsjISJYtW+YOw6ysLNatW8eDDz7okZ8pIiJSHqunNnz06FG2bNnC0aNHcTqdbNmyhS1btpCTk+NeJjY2lv/85z9A0XDd5MmTee655/jss8/Ytm0b9957L9HR0YwYMcJTZYqIiJThsRNynnrqKd555x33dLdu3QBYvnw5AwcOBGDPnj1kZma6l3n00Uc5d+4c48ePJyMjg379+rF06VJd4ygiItXKY+G4YMGCn7zG0Sh1nYPFYuGZZ57hmWee8VRZIiIiP8ljw6oiIiLeSuEoIiJSisJRRESklBpzh5yqUnwcMzs722ev7XE4HOTm5pKVlaU+8NE+8PX2g/rA19sPRTkAZc9vuRK1LhyL74gQExNjciUiIlITpKenU79+/QqtU+vCsWHDhkDRdZYV7YzaovgWeseOHSMkxDcf6OvrfeDr7Qf1ga+3HyAzM5NmzZq5c6Eial04Wq1Fh1Hr16/vsx+IYiEhIeoDH+8DX28/qA98vf3wYy5UaB0P1CEiIuLVFI4iIiKl1LpwtNvtTJs2rdwndfgK9YH6wNfbD+oDX28/XF0fWIzKnOMqIiJSi9W6PUcREZGrpXAUEREpReEoIiJSisJRRESkFJ8Ix88//5xevXoRFBREaGgoI0aMMLukapefn0/Xrl2xWCxs2bLF7HKqzeHDhxk7diwxMTEEBQXRqlUrpk2bRkFBgdmledScOXNo0aIFgYGB9OrVi/Xr15tdUrWYMWMG1113HfXq1SM8PJwRI0awZ88es8sy1YsvvojFYmHy5Mlml1JtTpw4wW9+8xsaNWpEUFAQnTp14vvvv6/QNmp9OH7yySfcc889jBkzhq1bt/Ldd99x1113mV1WtXv00UeJjo42u4xqt3v3blwuF/PmzWPHjh3MmjWLuXPn8sc//tHs0jzmo48+IjExkWnTprFp0ya6dOlCQkICqampZpfmcStXrmTChAmsXbuWpKQkHA4HQ4cO5dy5c2aXZooNGzYwb948OnfubHYp1ebs2bP07dsXf39//ve//7Fz505mzpxJaGhoxTZk1GIOh8O45pprjL/97W9ml2KqJUuWGLGxscaOHTsMwNi8ebPZJZnqpZdeMmJiYswuw2N69uxpTJgwwT3tdDqN6OhoY8aMGSZWZY7U1FQDMFauXGl2KdUuOzvbaNOmjZGUlGQMGDDAmDRpktklVYvHHnvM6Nev31Vvp1bvOW7atIkTJ05gtVrp1q0bUVFR3HTTTWzfvt3s0qpNSkoK48aNY+HChQQHB5tdTo2QmZlZqRsRe4OCggI2btxIfHy8e57VaiU+Pp41a9aYWJk5MjMzAWrt/+/LmTBhArfcckuJz4Iv+Oyzz+jRowcjR44kPDycbt268dZbb1V4O7U6HA8ePAjA008/zZNPPsnixYsJDQ1l4MCBnDlzxuTqPM8wDEaPHs0DDzxAjx49zC6nRti/fz+vvfYa999/v9mleMTp06dxOp1ERESUmB8REUFycrJJVZnD5XIxefJk+vbtS8eOHc0up1p9+OGHbNq0iRkzZphdSrU7ePAgb7zxBm3atOGLL77gwQcf5Pe//z3vvPNOhbbjleH4+OOPY7FYLvtVfKwJ4IknnuC2224jLi6O+fPnY7FY+Ne//mVyKyrvStv/2muvkZ2dzdSpU80uucpdaR9c7MSJEwwbNoyRI0cybtw4kyqX6jJhwgS2b9/Ohx9+aHYp1erYsWNMmjSJ999/n8DAQLPLqXYul4vu3bvzwgsv0K1bN8aPH8+4ceOYO3duhbbjlY+smjJlCqNHj77sMi1btuTUqVMAtG/f3j3fbrfTsmVLjh496skSPepK2//111+zZs2aMvcV7NGjB3fffXeF/yVVk1xpHxQ7efIkgwYNok+fPrz55psers48jRs3xmazkZKSUmJ+SkoKkZGRJlVV/SZOnMjixYtZtWoVTZo0MbucarVx40ZSU1Pp3r27e57T6WTVqlW8/vrr5OfnY7PZTKzQs6Kiokr8zQdo164dn3zySYW245XhGBYWRlhY2E8uFxcXh91uZ8+ePfTr1w8Ah8PB4cOHad68uafL9Jgrbf9f//pXnnvuOff0yZMnSUhI4KOPPqJXr16eLNHjrrQPoGiPcdCgQe6Rg8o8281bBAQEEBcXx7Jly9yXLLlcLpYtW8bEiRPNLa4aGIbBQw89xH/+8x9WrFhBTEyM2SVVu8GDB7Nt27YS88aMGUNsbCyPPfZYrQ5GgL59+5a5fGfv3r0V/5t/1af01HCTJk0yrrnmGuOLL74wdu/ebYwdO9YIDw83zpw5Y3Zp1e7QoUM+d7bq8ePHjdatWxuDBw82jh8/bpw6dcr9VVt9+OGHht1uNxYsWGDs3LnTGD9+vNGgQQMjOTnZ7NI87sEHHzTq169vrFixosT/69zcXLNLM5Uvna26fv16w8/Pz3j++eeNffv2Ge+//74RHBxsvPfeexXaTq0Px4KCAmPKlClGeHi4Ua9ePSM+Pt7Yvn272WWZwhfDcf78+QZQ7ldt9tprrxnNmjUzAgICjJ49expr1641u6Rqcan/1/Pnzze7NFP5UjgahmEsWrTI6Nixo2G3243Y2FjjzTffrPA29MgqERGRUmrvwRcREZFKUjiKiIiUonAUEREpReEoIiJSisJRRESkFIWjiIhIKQpHERGRUhSOIiIipSgcRURESlE4ioiIlKJwFBERKUXhKFJLpKWlERkZyQsvvOCet3r1agICAli2bJmJlYl4H914XKQWWbJkCSNGjGD16tW0bduWrl278vOf/5xXXnnF7NJEvIrCUaSWmTBhAl999RU9evRg27ZtbNiwAbvdbnZZIl5F4ShSy5w/f56OHTty7NgxNm7cSKdOncwuScTr6JijSC1z4MABTp48icvl4vDhw2aXI+KVtOcoUosUFBTQs2dPunbtStu2bZk9ezbbtm0jPDzc7NJEvIrCUaQWeeSRR/j444/ZunUrdevWZcCAAdSvX5/FixebXZqIV9GwqkgtsWLFCmbPns3ChQsJCQnBarWycOFCvvnmG9544w2zyxPxKtpzFBERKUV7jiIiIqUoHEVEREpROIqIiJSicBQRESlF4SgiIlKKwlFERKQUhaOIiEgpCkcREZFSFI4iIiKlKBxFRERKUTiKiIiU8v9PhNwyw2HgAwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(-6, 6, 121)\n",
        "y = (np.exp(x)- np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.xlim(-6, 6)\n",
        "plt.xlabel('x')\n",
        "plt.title('tanh function')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w487TaiNfrSX"
      },
      "source": [
        "## 사전 작업\n",
        "\n",
        "문장 분류 모델을 학습시키기 위한 사전 작업을 진행해보겠습니다. 데이터 셋을 불러오고, 토크나이저와 데이터 셋, 데이터 로더를 작성하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJje6_c8if8O"
      },
      "source": [
        "### 데이터 셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_Evsl9EPXVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_LrsZApkHuv"
      },
      "source": [
        "### tokenizer 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnAHgVhbkLct",
        "outputId": "ff10b805-9581-4e87-ed01-dde4f27692b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /Users/user/miniconda3/lib/python3.10/site-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/user/miniconda3/lib/python3.10/site-packages (from tokenizers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.9.2)\n",
            "Requirement already satisfied: requests in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/user/miniconda3/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2022.12.7)\n",
            "\u001b[33mDEPRECATION: pytorch-lightning 1.8.3.post1 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: mecab-python 0.996-ko-0.9.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of mecab-python or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bn5_DkoKPYeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHhDkqzNkTC7"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BWN_gHkUkGQ1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, corpus_df, transform=None):\n",
        "        self.corpus_df = corpus_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.corpus_df.iloc[idx]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5HcUKRGPeio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7C2En_zs8i-"
      },
      "source": [
        "### DataLoader\n",
        "\n",
        "dataloader 구현 시에 배치 내 각 문장별 토큰 개수를 집계한 batch_lengths를 추가로 리턴해주도록 합니다. 이는 RNN 학습 시에 pack_padded_sequence를 사용하기 위함이입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp_y6g3JkcCd"
      },
      "outputs": [],
      "source": [
        "MAX_TOKENS = 256\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppR8whfbkpRL"
      },
      "outputs": [],
      "source": [
        "vocabs = tokenizer.get_vocab()\n",
        "pad_token = vocabs[\"[PAD]\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uyDIXfBLkfy1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def _tokenize(text):\n",
        "    tokens = tokenizer.encode(text).ids\n",
        "    tokens = tokens[:MAX_TOKENS]\n",
        "    token_tensor = torch.tensor(tokens, dtype=torch.long)\n",
        "    return token_tensor\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_text = [x[0] for x in batch]\n",
        "    batch_label = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
        "    batch_tokens = [_tokenize(x) for x in batch_text]\n",
        "    batch_padded = pad_sequence(batch_tokens, padding_value=pad_token)\n",
        "    return batch_padded, batch_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUtlPQyMPjfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cBk-c9Otgyu"
      },
      "source": [
        "### pack_padded_sequence\n",
        "\n",
        "padding을 추가하게 되면 시퀀스 뒤에 0이 붙게 됩니다. 이는 길이를 맞추기 위함으로 실제 의미는 없습니다. 그런데 이를 그대로 RNN에 전달하면, 추가된 0만큼 불필요한 계산을 하게 됩니다.\n",
        "\n",
        "이를 방지하기 위해서 torch가 제공하는 기능이 pack_padded_sequence입니다. 먼저 예시 문장들을 토큰화 한 뒤, 패딩을 채워보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X7M_2fr8kSSw"
      },
      "outputs": [],
      "source": [
        "samples = [\"꿀잼\", \"노잼 비추\", \"감동적인 대작!! 울면서 봤습니다.\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_-_WVmdQGRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgFY7xJIuMEH"
      },
      "source": [
        "이를 pack_padded_sequence를 이용해서 압축해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zbwpeBojQJmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZZl_2PCxfnQ"
      },
      "source": [
        "pack_padded_sequence 결과를 보면 기존에 0으로 채워졌던 부분들이 제거되고 데이터들이 일렬로 펼쳐진 것을 확인할 수 있습니다. batch_sizes는 각 행마다 0이 아닌 값들의 개수를 집계한 숫자입니다. sorted_index는 0이 아닌 토큰 값들이 많은 열을 정렬한 결과입니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CobcK8xbQKXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am2k65xSxqfM"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU7_307G1-p5"
      },
      "source": [
        "data는 결국 각 행마다 0이 아닌 값들을 일렬로 펼쳐서 이어붙인 결과로 볼 수 있습니다. batch_size와 sorted_index를 이용하면 원래의 형태로 복원이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfXcEhT01no0"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxVpH0xy-7IW"
      },
      "source": [
        "### pad_packed_sequence\n",
        "torch에서 제공하는 pad_packed_sequence 함수를 사용하면 다시 원래의 상태로 복원할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOR-cHKRQL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YdFtrVW_THZ"
      },
      "source": [
        "torch를 이용해서 RNN 모델을 학습시킬 때, 학습을 빠르게 진행시키기 위해서는 RNN 통과 전에 pack_padded_sequence를 해주고, RNN을 통과시킨 이후에 pad_padded_sequence를 해주어 보원시켜주면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_eoD_ik-0b"
      },
      "source": [
        "## RNN 문장 분류 모델 학습\n",
        "\n",
        "이제 RNN을 이용해서 문장을 분류하는 모델을 만들고, 이를 학습시켜보겠습니다. 전반적인 구조는 아래와 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK6LncCRDm_N"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/7.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LowjsglaoH"
      },
      "source": [
        "### RNN 문장 분류 모델 작성"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6K82_usOQOPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hxL5LPUpaHm"
      },
      "source": [
        "### 학습 코드 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F2vNYfrpXHx"
      },
      "outputs": [],
      "source": [
        "def get_mean(metrics):\n",
        "    return round(sum(metrics) / len(metrics), 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_r0I1Hepda7"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def train_model(model):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    acc_list = []\n",
        "    for x_train, y_train in tqdm(train_dataloader):\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "\n",
        "        outputs = model(x_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        acc = ((y_train == pred).sum() / len(y_train)).item()\n",
        "        acc_list.append(acc)\n",
        "    return get_mean(loss_list), get_mean(acc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSvqySNbpesx"
      },
      "outputs": [],
      "source": [
        "def validate_model(model):\n",
        "    model.eval()\n",
        "    loss_list = []\n",
        "    acc_list = []\n",
        "    for x_val, y_val in tqdm(val_dataloader):\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(x_val)\n",
        "            loss = criterion(outputs, y_val)\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            pred = torch.argmax(outputs, dim=1)\n",
        "            acc = ((y_val == pred).sum() / len(y_val)).item()\n",
        "            acc_list.append(acc)\n",
        "    return get_mean(loss_list), get_mean(acc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOnvI5N-pgJA"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def train_validate_model(model):\n",
        "    logs = defaultdict(list)\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_model(model)\n",
        "        val_loss, val_acc = validate_model(model)\n",
        "        logs[\"train_loss\"].append(train_loss)\n",
        "        logs[\"train_acc\"].append(train_acc)\n",
        "        logs[\"val_loss\"].append(val_loss)\n",
        "        logs[\"val_acc\"].append(val_acc)\n",
        "        print(f\"epoch {epoch + 1} train - loss: {train_loss} acc: {train_acc} val - loss: {val_loss} acc: {val_acc}\")\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IwLAPPCpire"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_logs(logs):\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "\n",
        "    ax0 = fig.add_subplot(1, 2, 1)\n",
        "    ax1 = fig.add_subplot(1, 2, 2)\n",
        "    ax0.plot(logs[\"train_loss\"], label=\"train\")\n",
        "    ax0.plot(logs[\"val_loss\"], label=\"val\")\n",
        "    ax0.legend()\n",
        "    ax0.set_title(\"loss\")\n",
        "\n",
        "    ax1.plot(logs[\"train_acc\"], label=\"train\")\n",
        "    ax1.plot(logs[\"val_acc\"], label=\"val\")\n",
        "    ax1.legend()\n",
        "    ax1.set_title(\"accuracy\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zno3lRi3pmBz"
      },
      "source": [
        "### 하이퍼 파라미터 셋팅"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swxhjuFWQRgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGkXmg0Fpp3C"
      },
      "source": [
        "### 학습"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrkO_dFqQST3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ey8n9siGt4r"
      },
      "source": [
        "## RNN 변형하기\n",
        "\n",
        "방금 전에는 RNN을 1개 층만 쌓아서 학습을 시켜보았습니다. 이번에는 RNN 기본 구조를 약간 변형하여 학습시키는 기법들에 대해서 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcL5y2HYHFHD"
      },
      "source": [
        "### bi-directional RNN\n",
        "\n",
        "hidden state를 등장한 순서대로 흘려보내는 방식과, 역순으로 흘려보내는 방식을 모두 학습시키는 방법입니다. 여기서 얻은 마지막 시점의 hidden state를 Fully Connected Layer에 통과시킨 후, 예측 결과를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaHhu73dHb2O"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/8.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h-NwGbiGQTjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUZrAzSwEF0D"
      },
      "source": [
        "### RNN을 여러층 쌓기\n",
        "\n",
        "방금 학습시킨 모델은 RNN을 1층만 쌓았습니다. RNN 레이어를 여러층 쌓고 싶다면, 모델을 만들 때, RNN layer에 num_layers 옵션을 변경해주면 됩니다. 한번 층을 추가하여 모델을 학습시켜보고 성능이 개선되는지 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Il6tJ6NWs4"
      },
      "source": [
        "![1.png](https://storage.googleapis.com/data-analytics-camp/week12_deeplearning_nlp/9.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gGB5NGk7QV99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Sj193aODBJ"
      },
      "source": [
        "## 정리\n",
        "\n",
        "이번 챕터에서는 RNN의 기본 개념과 torch를 이용해서 RNN을 학습시킬 수 있는 방법에 대해서 알아보았습니다. 그리도 bi-directional RNN과 multilayer RNN에 대해서 알아보았습니다. 구조가 다소 복잡하지만, 코드 구현은 간단했습니다.\n",
        "\n",
        "디테일한 내용들에 너무 구애받지 말고, 이전 혹은 다음 입력값의 hidden state를 현재 값을 예측할 때 사용한다는 기본 개념만 확실히 기억하고 넘어가면 충분합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QvBneaCPTzD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}